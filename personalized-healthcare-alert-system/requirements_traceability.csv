ID,Category,Requirement Description,Priority,Status,Implementation Details / How the App Addresses It
CO1,Core Objective,System can trigger health alerts to the user.,Must Have,Done,"The app shows different types of alerts (like ""Mild"" or ""Escalation"") when simulated health data goes outside safe ranges."
CO2,Core Objective,System can recommend actions for the user to take (health or medical).,Should Have,Partially Done,"Alert messages provide initial guidance. Explanations generated by the AI (when API key is present) now consider behavioral logs- potentially leading to more context-specific (though still general) advice. Highly detailed or dynamically adapting personalized plans are not yet implemented."
CO3,Core Objective,System can escalate alerts to a doctor or caregiver.,Must Have,Done,"The app has an ""Escalation"" alert level. The actual sending of a message to a doctor isn't built (it's a simulation)- but the system knows when it's needed."
CO4,Core Objective,System can stay passive and keep monitoring if everything is normal.,Must Have,Done,If simulated health data is normal- no alerts appear- and the system just keeps an eye on things.
CO5,Core Objective,The system's advice and alerts are personalized for each user.,Must Have,Partially Done,"Users can set thresholds. Behavioral logs (diet- mood) and simple pattern-based insights (e.g.- 'glucose often near high threshold') are now generated- making the system slightly more personalized. True ongoing learning is still pending."
CO6,Core Objective,The system continuously learns and improves its advice over time.,Must Have,Started,"The system now generates simple insights based on data patterns over a few days (e.g.- consistently low sleep- frequent high glucose). This is a very rudimentary first step towards 'learning' or identifying trends- but not true continuous machine learning."
CO7,Core Objective,The system follows ethical rules and medical safety guidelines.,Must Have,Started,"The project aims to be ethical. Some features are included- like explaining alerts and letting users opt-out of automatic escalation. Full safety checks and fairness measures would need more development."
FO1,Observation,System can take in live data from wearable devices (like heart rate- blood sugar- oxygen levels- sleep).,Must Have,Partially Done,"The app simulates receiving this data. It doesn't connect to actual wearable devices yet."
FO2,Observation,System can access organized patient health records (like medications- allergies- current illnesses).,Must Have,Partially Done,"Basic health record information is stored for the simulated user and used to help explain alerts. It doesn't connect to real hospital or doctor records."
FO3,Observation,System can analyze user's notes on diet- activity levels- and mood.,Should Have,Partially Done,"The app now allows users to log Diet (type- details- notes)- Mood (type- notes)- and Activity (type- duration- intensity- notes) through a form. These logs are displayed in the activity feed and are considered in risk assessment and alert explanations."
FO4,Observation,System can store and process all health data in a specific type of database (MongoDB).,Should Have,Started,"The app now uses browser localStorage to persist user data- health data stream- alerts- and behavioral logs across sessions. This simulates persistent storage- though it's not a full backend database like MongoDB."
FG1,Goals,System helps prevent health emergencies (like a stroke or very low blood sugar) by spotting risks early.,Must Have,Partially Done,"The alert system warns about dangerous readings. By incorporating behavioral context (e.g.- high glucose after high-carb meal vs. unexplained high glucose)- the system can potentially provide more nuanced early warnings- aiding in risk mitigation."
FG2,Goals,System tries to minimize incorrect alerts (false positives) so users don't get annoyed or ignore them.,Must Have,Started,"The app has some logic to avoid sending too many similar- non-critical alerts close together. Users can also dismiss alerts with feedback (e.g.- false alarm- expected). More advanced ways to reduce false alarms would need further development."
FG3,Goals,"System can personalize alert settings using smart- continuous learning methods (e.g.- PyTorch/TensorFlow).",Should Have,Started,"Manual threshold adjustment is present. The new 'insights' feature- while not directly adjusting thresholds- represents an initial step in analyzing patterns that could *eventually* inform adaptive thresholds. No automatic adjustment yet."
AC1,Agent Capabilities,System uses past health data- set rules- and smart learning models to figure out current health risks.,Must Have,Partially Done,"The app uses recent health data- user-defined thresholds- and now incorporates recent behavioral logs (diet- mood- activity) into its rule-based risk assessment. For example- a high glucose reading after a high-carb meal might be contextualized. True 'learned models' are still not implemented."
AC2,Agent Capabilities,"System can handle and combine different types of health information (like heart rate and blood sugar readings) using a mix of fixed rules and self-learning methods.",Should Have,Partially Done,"The system now considers health data (like glucose) alongside behavioral data (like diet logs or mood logs) in its rule-based logic- improving its ability to handle different types of signals. Self-learning methods are not yet used."
AC3,Agent Capabilities,If an unusual reading is detected- the system can issue a mild alert telling the patient to take corrective action.,Must Have,Done,The app shows "Mild" alerts with advice when simulated data is a bit off.
AC4,Agent Capabilities,If an unusual reading is detected- the system can issue an escalation alert to a doctor or caregiver.,Must Have,Done,The app shows "Escalation" alerts when simulated data is seriously off. (Actual notification is not part of this simulation).
AC5,Agent Capabilities,If an unusual reading is detected but the risk is low or uncertain- the system can log it and wait.,Must Have,Done,"If data is normal or only slightly off in a non-critical way (resulting in an ""Info"" alert- an Insight- or no alert)- the system effectively logs it and continues monitoring."
AC6,Agent Capabilities,For any smart learning parts- the system uses a tool (like MLFLOW) to keep track of different versions and manage retraining.,Could Have,Not Started,"Since there are no smart learning parts yet- this tracking isn't implemented. This is for managing more advanced background features."
AC7,Agent Capabilities,The system is deployed using cloud tools (like Azure MLOps) for continuous learning and updates.,Could Have,Not Started,"How the app is deployed and updated with advanced learning features is a background/infrastructure concern- not part of this frontend simulation."
TC1,Tech Constraints,All smart learning models are logged and tracked (e.g.- using MLFLOW).,Could Have,Not Started,Same as AC6. No smart learning models in the current app to track.
TC2,Tech Constraints,The system supports learning from multiple types of data inputs.,Should Have,Partially Done,"The system now explicitly uses both health metrics and behavioral logs (diet- mood- activity) in its decision-making for alerts and explanations- which is a step towards multi-modal processing- even if true 'learning' is rule-based currently."
TC3,Tech Constraints,The system can generate explanations for its alerts.,Must Have,Done,"Users can click a ""Why this alert?"" button to get an explanation- which is either a placeholder or generated by a real AI (Gemini) if configured."
TC4,Tech Constraints,The system allows for human oversight and ability to override its decisions (human-in-the-loop).,Should Have,Started,"Users can change their personal alert settings (thresholds)- which is a way to guide the system. They can also choose not to have serious alerts automatically escalated. They can dismiss alerts with feedback. Direct override of a single alert's risk level isn't implemented."
TC5,Tech Constraints,The system allows for customized alert settings (thresholds) per user- which can be learned/adjusted over time.,Must Have,Partially Done,"Users can customize their alert settings. The ""learned over time"" part (automatic adjustment) is addressed by initial 'insights' features but not fully implemented yet."
EC1,Ethical Constraints,The system must be understandable â€“ users can ask ""Why did I get this alert?"" and get a clear answer.,Must Have,Done,"The ""Why this alert?"" feature remains. If the Gemini API is used- explanations can now incorporate recent behavioral logs making them more contextually relevant and interpretable."
EC2,Ethical Constraints,The system must ensure data privacy and secure access to health information.,Must Have,Not Started,"This is a frontend simulation using localStorage- so real data privacy and security measures (which would be complex background features) are not implemented. User data is stored locally in the browser."
EC3,Ethical Constraints,The system uses methods to detect and prevent unfairness or bias in its recommendations- ensuring it doesn't create health disadvantages for different groups of people.,Should Have,Not Started,"Since the app doesn't yet make complex- learned recommendations- there's no bias detection implemented. This is an advanced ethical consideration for AI systems."
EC4,Ethical Constraints,The system allows patients to opt-out of having their alerts automatically escalated to doctors/caregivers- if legally okay.,Must Have,Done,"There's a setting in the app that lets users turn off automatic escalation. Alerts are then shown as serious but note that escalation was manually opted out."
